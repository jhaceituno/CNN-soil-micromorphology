{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn_experiments.ipynb","provenance":[{"file_id":"1JX7eugw4Mi6j0C8ac13YXYLoIFndrVvS","timestamp":1580743504545}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"jT_FXG5p3tzM"},"source":["%tensorflow_version 1.x\n","\n","from tensorflow.keras.applications.xception import Xception\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from keras.applications.resnet_v2 import ResNet50V2\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n","from tensorflow.keras.applications.mobilenet import MobileNet\n","from tensorflow.keras.applications.densenet import DenseNet121\n","from tensorflow.keras.applications.nasnet import NASNetMobile\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","\n","from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import RMSprop\n","\n","from google.colab import drive\n","from math import ceil\n","import matplotlib.pyplot as plt\n","import datetime\n","import numpy as np\n","import os\n","\n","# Experiment configuration\n","USING_SPLITS = False\n","NET = 'inceptionresnetv2'  # Must be one of the available networks below\n","current_folder = '/content/gdrive/My Drive/public/sediments/'\n","\n","samples = 'splits' if USING_SPLITS else 'images'\n","drive.mount('/content/gdrive')\n","!cp \"{current_folder}{samples}.tar.gz\" /tmp\n","!tar xzvf /tmp/{samples}.tar.gz\n","BASE = '/content/{}/folds'.format(samples)\n","ALL_TRAIN_SET_PATH = '/content/splits/train' if USING_SPLITS else '/content/images/training_set'\n","TEST_SET_PATH = '/content/splits/test' if USING_SPLITS else '/content/images/test_set'\n","BASE_RESULTS = current_folder + 'results/' + samples\n","\n","available_networks = {\n","    'xception': Xception,\n","    'vgg16': VGG16,\n","    'vgg19': VGG19,\n","    'resnet50': ResNet50,\n","    'resnet50v2': ResNet50V2,\n","    'inceptionv3': InceptionV3,\n","    'inceptionresnetv2': InceptionResNetV2,\n","    'mobilenet': MobileNet,\n","    'densenet': DenseNet121,\n","    'nasnetmobile': NASNetMobile,\n","    'mobilenetv2': MobileNetV2\n","}\n","\n","CLASSES = ['background', 'chambers', 'channels', 'packing voids', 'planes', 'vesicles', 'vughs']\n","\n","\n","def plot_history(histories, base_results, network, fold, additional_suffix_str, key='acc'):\n","    plt.figure(figsize=(16,10))\n","  \n","    val_key = 'val_' + key\n","    for name, history in histories:\n","        if val_key in history.history:\n","            val = plt.plot(history.epoch, history.history[val_key], '--', label=name.title() + ' Val')\n","            plt.plot(history.epoch, history.history[key], color=val[0].get_color(), label=name.title() + ' Train')\n","        else:\n","            plt.plot(history.epoch, history.history[key], color='b', label=name.title() + ' Train')\n","\n","    plt.xlabel('Epochs')\n","    plt.ylabel(key.replace('_', ' ').title())\n","    plt.legend()\n","    plt.xlim([0, max(history.epoch)])\n","    plt.savefig('{0}/{1}/fold_{2}_{3}_acc_history.png'.format(base_results, network, fold, additional_suffix_str),\n","                dpi=None, facecolor='w', edgecolor='w',  orientation='portrait', papertype=None,\n","                format=None, transparent=False, bbox_inches='tight', pad_inches=0.5, frameon=None)\n","\n","\n","def build_model(network, input_size):\n","    base_model = available_networks[network](input_tensor=Input(shape=(input_size, input_size, 3)),\n","                                             weights='imagenet', include_top=False)\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    predictions = Dense(7, activation='softmax')(x)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    return base_model, model\n","\n","\n","def model_fine_tuning(network, base_model, model, train_batches, val_batches, EPOCHS_FINE_TUNING,\n","                      STEPS_PER_EPOCH, VALIDATION_STEPS, base_results, fold):\n","    print('Trainable weights before freezing the conv base: {}'.format(len(model.trainable_weights)))\n","    base_model.trainable = False\n","    print('Trainable weights after freezing the conv base: {}'.format(len(model.trainable_weights)))\n","    model.compile(RMSprop(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n","    print('Epochs: {}'.format(EPOCHS_FINE_TUNING))\n","    print('Steps per epoch: {}'.format(STEPS_PER_EPOCH))\n","    print('Validation steps: {}'.format(VALIDATION_STEPS))\n","    print('Fold {} - Starting fine-tuning...'.format(fold))\n","    a = datetime.datetime.now()\n","    model_history = model.fit_generator(train_batches, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS_FINE_TUNING,\n","                                        verbose=2) if val_batches is None else \\\n","                    model.fit_generator(train_batches, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS_FINE_TUNING,\n","                                        validation_data=val_batches, validation_steps=VALIDATION_STEPS, verbose=2)\n","    b = datetime.datetime.now()\n","    print('Elapsed time for fine-tuning: {}'.format(b - a))\n","    plot_history([('model', model_history)], base_results, network, fold, 'fine_tuning')\n","    return model_history, base_model, model\n","\n","  \n","def model_deep_tuning(network, input_size, base_model, model, train_batches, val_batches, test_path,\n","                      EPOCHS_DEEP_TUNING, STEPS_PER_EPOCH, VALIDATION_STEPS, base_results, fold, results_file):\n","    print('Trainable weights before unfreezing the conv base: {}'.format(len(model.trainable_weights)))\n","    base_model.trainable = True\n","    print('Trainable weights after unfreezing the conv base: {}'.format(len(model.trainable_weights)))\n","    model.compile(RMSprop(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n","    print('Fold {} - Starting deep-tuning...'.format(fold))\n","    a = datetime.datetime.now()\n","    if val_batches is None:\n","        model_history = model.fit_generator(train_batches, steps_per_epoch=STEPS_PER_EPOCH,\n","                                            epochs=EPOCHS_DEEP_TUNING, verbose=2)\n","        model.save_weights('{0}/{1}/fold_{2}_w_net.h5'.format(base_results, network, fold))\n","        test_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(\n","            test_path, target_size=(input_size, input_size), batch_size=BATCH_SIZE, classes=CLASSES)\n","        loss, acc = model.evaluate_generator(test_batches)\n","        results_file.write('Fold {0} - Test Acc: {1}\\n'.format(fold, acc))\n","    else:\n","        model_history = model.fit_generator(train_batches, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS_DEEP_TUNING,\n","                                            validation_data=val_batches, validation_steps=VALIDATION_STEPS, verbose=2)\n","        loss, acc = model.evaluate_generator(val_batches)\n","        results_file.write('Fold {0} - Test Acc: {1}\\n'.format(fold, acc))\n","    b = datetime.datetime.now()\n","    print('Elapsed time for deep-tuning: {}'.format(b - a))\n","    plot_history([('model', model_history)], base_results, network, fold, 'deep_tuning')\n","    results_file.close()\n","    return model_history\n","\n","\n","results_path = BASE_RESULTS + '/' + NET\n","os.makedirs(results_path, exist_ok=True)\n","\n","# Network parameters\n","NUM_FOLDS = 1\n","input_size = 224\n","BATCH_SIZE = 32\n","EPOCHS_FINE_TUNING = 30\n","EPOCHS_DEEP_TUNING = 50 \n","all_acc_histories = []\n","\n","# For loop repeating the training for each fold: fine-tuning freezing the base model\n","for fold in range(1, NUM_FOLDS + 1):\n","    fold_path = BASE + '/fold_' + str(fold)\n","    train_path = fold_path + '/training_set'\n","    val_path = fold_path + '/validation_set'\n","    results_file = open(results_path + '/info.txt', 'w' if fold == 1 else 'a') \n","\n","    base_model, model = build_model(NET, input_size)\n","    train_generator = ImageDataGenerator(\n","        rescale=1. / 255, rotation_range=30, vertical_flip=True, horizontal_flip=True, zoom_range=[0.8, 1.2]\n","        ).flow_from_directory(train_path, target_size=(input_size, input_size), batch_size=BATCH_SIZE, classes=CLASSES)\n","    val_generator = ImageDataGenerator(rescale=1. / 255).flow_from_directory(\n","        val_path, target_size=(input_size, input_size), batch_size=BATCH_SIZE, classes=CLASSES)\n","    \n","    STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n","    STEP_SIZE_VALID = val_generator.n // val_generator.batch_size\n"," \n","    model_history, base_model, model = model_fine_tuning(\n","        NET, base_model, model, train_generator, val_generator, EPOCHS_FINE_TUNING, STEP_SIZE_TRAIN,\n","        STEP_SIZE_VALID, BASE_RESULTS, str(fold) + '_pre')\n","    all_acc_histories.append(model_history.history['val_acc'])\n","\n","print(all_acc_histories)\n","average_acc_history = [np.mean([x[i] for x in all_acc_histories]) for i in range(EPOCHS_FINE_TUNING)]\n","print(average_acc_history)\n","max_acc_epoch = average_acc_history.index(max(average_acc_history)) + 1\n","print('Best epoch for fine-tuning: {}'.format(max_acc_epoch))\n","\n","all_acc_histories_deep = []\n","# For loop repeating the training for each fold: deep-tuning (train all layers)\n","for fold in range(1, NUM_FOLDS + 1):\n","    fold_path = BASE + '/fold_' + str(fold)\n","    train_path = fold_path + '/training_set'\n","    val_path = fold_path + '/validation_set'\n","    results_file = open(results_path + '/info.txt', 'w' if fold == 1 else 'a') \n","\n","    base_model, model = build_model(NET, input_size)\n","    train_generator = ImageDataGenerator(\n","        rescale=1. / 255, rotation_range=30, vertical_flip=True, horizontal_flip=True, zoom_range=[0.8, 1.2]\n","        ).flow_from_directory(train_path, target_size=(input_size, input_size), batch_size=BATCH_SIZE, classes=CLASSES)\n","    val_generator = ImageDataGenerator(rescale=1. / 255).flow_from_directory(\n","        val_path, target_size=(input_size, input_size), batch_size=BATCH_SIZE, classes=CLASSES)\n","    \n","    STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n","    STEP_SIZE_VALID = val_generator.n // val_generator.batch_size\n","    \n","    # Do a fine-tuning first for the added top layers, using the best epoch of the fine-tuning performed previously\n","    model_history, base_model, model = model_fine_tuning(\n","        NET, base_model, model, train_generator, val_generator, max_acc_epoch,\n","        STEP_SIZE_TRAIN, STEP_SIZE_VALID, BASE_RESULTS, fold)\n","    # Deep-tuning: train all layers\n","    model_history = model_deep_tuning(\n","        NET, input_size, base_model, model, train_generator, train_generator, TEST_SET_PATH, EPOCHS_DEEP_TUNING,\n","        STEP_SIZE_TRAIN, STEP_SIZE_VALID, BASE_RESULTS, fold, results_file)\n","    all_acc_histories_deep.append(model_history.history['val_acc'])\n","\n","print(all_acc_histories_deep)\n","average_acc_history_deep = [np.mean([x[i] for x in all_acc_histories_deep]) for i in range(EPOCHS_DEEP_TUNING)]\n","print(average_acc_history_deep)\n","max_acc_epoch_deep = average_acc_history_deep.index(max(average_acc_history_deep)) + 1\n","print('Best epoch for deep-tuning: {}'.format(max_acc_epoch_deep))\n","\n","# Final training with all images using the best epoch found for fine and deep tuning\n","results_file = open(results_path + '/final_train_test.txt', 'w') \n","results_file.write('Fine-tuning epochs: {}\\n'.format(max_acc_epoch))\n","results_file.write('Deep-tuning epochs: {}\\n'.format(max_acc_epoch_deep))\n","base_model, model = build_model(NET, input_size)\n","train_generator = ImageDataGenerator(\n","    rescale=1. / 255, rotation_range=30, vertical_flip=True, horizontal_flip=True, zoom_range=[0.8, 1.2]\n","    ).flow_from_directory(\n","        ALL_TRAIN_SET_PATH, target_size=(input_size, input_size), batch_size=BATCH_SIZE, classes=CLASSES)\n","STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n","\n","model_history, base_model, model = model_fine_tuning(NET, base_model, model, train_generator, None, max_acc_epoch,\n","                                                     STEP_SIZE_TRAIN, None, BASE_RESULTS, 'final')\n","model_history = model_deep_tuning(NET, input_size, base_model, model, train_generator, None, TEST_SET_PATH,\n","                                  max_acc_epoch_deep, STEP_SIZE_TRAIN, None, BASE_RESULTS, 'final', results_file)\n"],"execution_count":null,"outputs":[]}]}